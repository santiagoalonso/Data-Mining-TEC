{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#Tables and matrices\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Stats \n",
    "import scipy.stats as st\n",
    "\n",
    "#Graphs\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, HBox, VBox, Layout\n",
    "from graphviz import Source\n",
    "from graphviz import Digraph\n",
    "import altair as alt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Meeting Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Santiago Alonso-Díaz, PhD\n",
    "\n",
    "Universidad Javeriana"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img src=\"img/2_CB/Thomas_Bayes.gif\" width = \"300\" height = '300'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The theorem:\n",
    "\n",
    "$$ p(\\theta|y) = \\frac{p(y|\\theta)p(\\theta)}{p(y)}$$\n",
    "\n",
    "Think of `p` as a distribution (continuous or discrete; there are many types):\n",
    "\n",
    "<center><img src=\"img/2_CB/normal_poisson.svg\" width = \"800\" height = '700'></center>\n",
    "\n",
    "\n",
    "$\\theta$: hipotheses; $y$: data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The theorem:\n",
    "\n",
    "$$ p(\\theta|y) = \\frac{p(y|\\theta)p(\\theta)}{p(y)}$$\n",
    "\n",
    "Denominator: probability of the data, under all the hypotheses:\n",
    "\n",
    "$$ p(\\theta|y) = \\frac{p(y|\\theta)p(\\theta)}{\\int{p(y|\\theta)p(\\theta)d\\theta}}$$\n",
    "\n",
    "The denominator is called the `marginal`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The marginal is, in most cases, a constant. It keeps the integral of the posterior probability between 0 and 1. The marginal is hard to calculate, so you will mostly see the proportional version of Bayes theorem:\n",
    "\n",
    "$$ p(\\theta|y) \\propto p(y|\\theta)p(\\theta)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "But let's take a step back. What is a probability?\n",
    "\n",
    "* Medida positiva (+) de eventos (E) en un espacio (H)\n",
    "* La probabilidad de todo el espacio (H) es 1\n",
    "* La probabilidad de eventos mutuamente excluyentes se puede sumar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What is a probability? Two basic (and some time opposite) interpretations: \n",
    "<center> <p style = 'font-size = 20px'> Frequentist vs. Belief</p> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What is the probability of head?\n",
    "<center><img src=\"img/2_CB/Coin_cara.png\" width = \"150\" height = '150'></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What is the probability of head after these 7 outcomes?\n",
    "<center><img src=\"img/2_CB/Coin_cara_sello.png\" width = \"340\" height = '340'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What is the probability of winning a Nobel prize?\n",
    "<center><img src=\"img/2_CB/Nobel_Prize.png\" width = \"240\" height = '240'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What is the probability of winning a Nobel prize? Can we use frequencies? World population: 7800 million.\n",
    "\n",
    "|Nobel|Ganadores|\n",
    "|:-----:|:---------:|\n",
    "|Física|213|\n",
    "|Química|184|\n",
    "|Medicina|219|\n",
    "|Literatura|116|\n",
    "|Paz|134|\n",
    "|Economía|84|\n",
    "|**Total**|950|\n",
    "\n",
    "Source: nobelprize.org (2020)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Frequentist probability: frequency of events; there is a point estimate\n",
    "\n",
    "|Problem|Data|$\\theta$|\n",
    "|:-------:|:-------:|:-------:|\n",
    "|<img src=\"img/2_CB/Coin_cara.png\" width = \"175\" height = '175'>|1 head, 6 tails|$\\frac{1}{7}$|\n",
    "\n",
    "Bayesian probability: beliefs; there is a distribution over the potential estimate\n",
    "\n",
    "|Problem|Data|$\\theta$|\n",
    "|:-------:|:-------:|:-------:|\n",
    "|<img src=\"img/2_CB/Coin_cara.png\" width = \"175\" height = '175'>|1 head, 6 tails|<img src=\"img/2_CB/beta.svg\" width = \"200\" height = '200'>|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Bayes lure: \n",
    "\n",
    "We can combine prior knowledge about an hypothesis ($p(\\theta))$ and update that prior with data to obtain a new posterior belief/knowledge ($p(\\theta|data)$).\n",
    "\n",
    "$$ p(\\theta|data) = \\frac{p(data|\\theta)p(\\theta)}{p(data)}$$\n",
    "\n",
    "Today's posterior is the future prior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Prior: lands heads 50% of the times. <br>\n",
    "Data = after 10 throws, only lands heads once <br>\n",
    "Posterior = lands heads 35% of the times (under some likelihood)\n",
    "\n",
    "Prior: 30% in Colombia has COVID-19. <br>\n",
    "Data = positive test <br>\n",
    "Posterior = 70% you have the virus (under some likelihood)\n",
    "\n",
    "Prior: the code is huge, 80% that there is a bug. <br>\n",
    "Data = a week without errors <br>\n",
    "Posterior = 33.781% there is a bug (under some likelihood)\n",
    "\n",
    "Prior: every even number is the sum of two primes (Goldbach conjecture)<br>\n",
    "Data: there is not a single counterexample (so far)<br>\n",
    "Posterior: 99% conjecture is true (under some likelihood).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's visualize the coin example\n",
    "\n",
    "Objective: infer the posterior probability of heads, given some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Interactive plot. Belief update after data\n",
    "theta_real = 0.375 #heads probability (this is the one we want to infer)\n",
    "def posterior_beta(lanzamientos, a, b):\n",
    "    #Likelihood: observed heads follow a Bernoulli\n",
    "    #Prior: Beta with parameters a, b \n",
    "    \n",
    "    #Experiment (data)\n",
    "    np.random.seed(seed=1144)\n",
    "    caras = st.bernoulli.rvs(theta_real, size=lanzamientos).sum() #heads\n",
    "    \n",
    "    #Prior (belief)\n",
    "    prior_par = np.array([a,b]) \n",
    "    \n",
    "    #Posterior (updated belief)\n",
    "    #Later in the course we will explain where do the a and b parameters come from.\n",
    "    #They come from an analytical derivation of a bernoulli-beta model.\n",
    "    nsims = 10000\n",
    "    a = caras + prior_par[0]\n",
    "    b = lanzamientos - caras + prior_par[1]\n",
    "    posterior_samples = np.sort(st.beta.rvs(a = a, b = b, size = nsims)) \n",
    "    posterior_pdf = st.beta.pdf(x = posterior_samples, a = a, b = b)\n",
    "    \n",
    "    #Graph\n",
    "    fig, ax = plt.subplots(1,1, figsize=(5,5))\n",
    "    idx1 = np.where(posterior_samples>=np.percentile(posterior_samples,q=2.5))[0][0]\n",
    "    idx2 = np.where(posterior_samples>=np.percentile(posterior_samples,q=97.5))[0][0]\n",
    "    text = \"[\" + str(np.round(posterior_samples[idx1],3)) +\\\n",
    "    \",\" + str(np.round(a/(a+b),3)) +\\\n",
    "    \",\" + str(np.round(posterior_samples[idx2],3)) + \"]\"\n",
    "    ax.plot(posterior_samples, posterior_pdf,'r-', lw=5, alpha=0.8, \n",
    "            label = '[2.5%, mean, 97.5%]  = ' + text)\n",
    "    ax.set_title('Posterior (belief of heads) \\n Real prob.: ' + str(theta_real))\n",
    "    ax.set_xlabel('Heads probability')\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_xlim([0,1])\n",
    "    ax.set_ylim([0,1.2*np.max(posterior_pdf)])\n",
    "    ax.legend(loc = 'upper right')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e565c95fe80b45afa23b1897d62b82cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(BoundedIntText(value=3, description='Throws: ', max=1000000, min=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w_experimento = widgets.BoundedIntText(value = 3, description = 'Throws: ',\n",
    "                                      min = 1, max = 1000000)\n",
    "#Beta(1,1) es uniforme. Busque en internet la distribucion Beta; conozcola.\n",
    "w_prior_par_a = widgets.BoundedIntText(value = 1, description = 'Prior par a: ',\n",
    "                        min = 1, max = 1000000)\n",
    "w_prior_par_b = widgets.BoundedIntText(value = 1, description = 'Prior par b: ',\n",
    "                        min = 1, max = 1000000)\n",
    "out = widgets.interactive_output(posterior_beta, \n",
    "                                 {'lanzamientos': w_experimento, \n",
    "                                  'a': w_prior_par_a, 'b': w_prior_par_b})\n",
    "left_widgets = VBox([w_experimento])\n",
    "right_widgets = VBox([w_prior_par_a, w_prior_par_b])\n",
    "top = HBox([left_widgets, right_widgets])\n",
    "VBox([top, out])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Example 2; based on Kahneman, 2011, Thinking, Fast, and Slow.\n",
    "\n",
    "Objective: guess the profession.\n",
    "\n",
    "Charles is shy, kind, but with little interest in socializing. He likes order and is precise in his work.\n",
    "\n",
    "¿Electrical Engineer or Business major?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Kahneman found that the majority would say electrical engineer. <br>\n",
    "Why? <br>\n",
    "Judgment guided by the likelihood that Charles' observables are more likely in an engineer? <br>\n",
    "Do we neglect the prior that more people study Business?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "#Example: electrical engineer or business major.\n",
    "#Based on: Davidson-Pilon (2015).\n",
    "def posterior_beta_carlos(a_prior, b_prior, data_experimento):\n",
    "    #Bayes\n",
    "    prior_par = np.array([a_prior,b_prior])\n",
    "    prior_mean = [a_prior/(a_prior+b_prior), 1 - a_prior/(a_prior+b_prior)]\n",
    "    nsims = 10000\n",
    "    juicio_ing = data_experimento[0] #people that said engineer\n",
    "    juicio_todos = data_experimento.sum() #whole sample\n",
    "    a =  juicio_ing + prior_par[0] #we will see later in the course why a, b take this form (bernoulli-beta model)\n",
    "    b = juicio_todos - juicio_ing + prior_par[1]\n",
    "    posterior_mean = [a/(a+b), 1 - a/(a+b)] #With uniform prior\n",
    "    \n",
    "    a =  juicio_ing + prior_real[0]\n",
    "    b = juicio_todos - juicio_ing + prior_real[1]\n",
    "    posterior_real_mean = [a/(a+b), 1 - a/(a+b)] #With a data-based prior\n",
    "    \n",
    "    #Graph\n",
    "    #With uniform prior\n",
    "    fig, ax = plt.subplots(1,2, figsize=(12, 3))\n",
    "    colors = [\"#348ABD\", \"#A60628\"]\n",
    "    fig.suptitle('Prior and posteriors of professions')\n",
    "    ax[0].bar([0, .7], prior_real, alpha=0.70, width=0.25, color=colors[0], label=\"Prior (data-based)\",\n",
    "            lw=\"3\", edgecolor=\"#348ABD\")\n",
    "    ax[0].bar([0+0.25, .7+0.25], posterior_mean, alpha=0.7,\n",
    "            width=0.25, color=colors[1], label=\"Posterior with uniform prior\",\n",
    "            lw=\"3\", edgecolor=\"#A60628\")\n",
    "    ax[0].set_xticks([0.20, 0.95])\n",
    "    ax[0].set_xticklabels([\"Engineer\", \"Business\"])\n",
    "    #ax[0].set_title(\"Prior real y posterior de las profesiones de Carlos\")\n",
    "    ax[0].set_ylabel(\"Probability\")\n",
    "    ax[0].set_ylim([0,1.1])\n",
    "    ax[0].legend(loc=\"upper right\");\n",
    "    \n",
    "    #Con prior real\n",
    "    ax[1].bar([0, .7], prior_real, alpha=0.70, width=0.25, color=colors[0], label=\"Prior (data-based)\",\n",
    "            lw=\"3\", edgecolor=\"#348ABD\")\n",
    "    ax[1].bar([0+0.25, .7+0.25], posterior_real_mean, alpha=0.7,\n",
    "            width=0.25, color=colors[1], label=\"Posterior with data-based prior\",\n",
    "            lw=\"3\", edgecolor=\"#A60628\")\n",
    "    ax[1].set_xticks([0.20, 0.95])\n",
    "    ax[1].set_xticklabels([\"Engineer\", \"Business\"])\n",
    "    #ax[1].set_title(\"Prior real y posterior de las profesiones de Carlos\")\n",
    "    ax[1].set_ylabel(\"Probability\")\n",
    "    ax[1].set_ylim([0,1.1])\n",
    "    ax[1].legend(loc=\"upper right\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data experiment: \n",
      "Electrical: 133798\n",
      "Business: 44600\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Real data: Colombia, data min. educacion 2001-2018.\n",
    "grad = np.array([24763, 153635]) #number of degrees [electrical, business]\n",
    "prior_real = [grad[0]/grad.sum(), grad[1]/grad.sum()] \n",
    "\n",
    "#Experiment. We ask a lot of people and found the following number of\n",
    "#people saying that Charles is: [electrical engineer, business major]\n",
    "data_experimento = np.array([round(grad.sum()*3/4), round(grad.sum()*1/4)]) \n",
    "print('Data experiment: \\nElectrical: ' + str(data_experimento[0]) + \"\\nBusiness: \"  + str(data_experimento[1]))\n",
    "\n",
    "#The real prior (blue), looks different from the observed beliefs (posterior, red)\n",
    "#The posterior is robust to different priors. People are biased. \n",
    "#They use the likelihood: the probability of Carlos personality, given the hypothesis that\n",
    "#he is an engineer \n",
    "posterior_beta_carlos(1, 1, data_experimento) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "What hypotheses $\\theta$ are interesting in cognitive science, economics, and artificial intelligence?\n",
    "\n",
    "* Risk aversion\n",
    "* Impulsivity (e.g. intertemporal discounting)\n",
    "* Subjective utility\n",
    "* Institutional trust\n",
    "* Selfishness \n",
    "* Altruism\n",
    "* Empathy\n",
    "* Psychopathy\n",
    "* Perceptual sensitivity\n",
    "* Math ability\n",
    "* Capacity (in bits) of a learner\n",
    "* Pragmatic interpretation of a sentence\n",
    "* Object identity in the visual field\n",
    "* Creativity\n",
    "* Uncertainty\n",
    "* Others\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Analytical derivation of a Beta posterior \n",
    "### Likelihood: Bernoulli\n",
    "### Prior: Beta\n",
    "### Posterior: Beta (we will prove this)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Data: binary and independent (e.g. heads-tails; point-no point; pass-fail; happy-unhappy)\n",
    "\n",
    "Objective: to estimate the latent probability of one of the binary outcomes\n",
    "\n",
    "Model: Beta (prior) - Bernoulli (LH)\n",
    "\n",
    "<center><img src=\"img/2_CB/beta_bernoulli.svg\" width = \"600\" height = '600'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Where are we heading?\n",
    "\n",
    "Demonstrate that the posterior, like the prior, is a Beta distribution. When the posterior ends up with the same form as the prio, we say that we have a `conjugate prior`.\n",
    "\n",
    "In other words, we will demonstrate that the the conjugate prior of a Bernoulli is a Beta (https://en.wikipedia.org/wiki/Conjugate_prior).\n",
    "\n",
    "Conjugate priors are useful when we are interested in obtaining a mathematical expression for the posterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Bernoulli (pmf); Support: n = 0 o 1; Parameters: p = [0,1] \n",
    "$$P(n) = p^n(1-p)^{1-n}$$\n",
    "\n",
    "Beta (pdf); Support: x = [0,1]; Parameters: $\\alpha$ y $\\beta$ > 0; Others: B = Función Beta\n",
    "\n",
    "$$P(x) = \\frac{x^{\\alpha-1}(1-x)^{\\beta-1}}{B(\\alpha,\\beta)}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084cd5aec18e4a5c95160b7895e1318c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(BoundedIntText(value=1, description='a (num): ', max=1000000, min…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def beta_bernoulli(p, a, b):\n",
    "    fig, ax = plt.subplots(1,2,figsize = (10.5,4))\n",
    "    x = np.linspace(st.beta.ppf(0.001, a, b), st.beta.ppf(0.999, a, b), 100)\n",
    "    ax[0].plot(x, st.beta.pdf(x, a, b), 'r-', lw=5, alpha=0.6, label='beta pdf')\n",
    "    ax[0].set_xlim([0,1]);\n",
    "    ax[0].set_title('Prior')\n",
    "    ax[0].legend()\n",
    "\n",
    "    x = np.linspace(st.bernoulli.ppf(0.001, p), st.bernoulli.ppf(0.999, p),2)\n",
    "    ax[1].plot(x, st.bernoulli.pmf(x, p), 'bo', ms=8, label='bernoulli pmf')\n",
    "    ax[1].vlines(x, 0, st.bernoulli.pmf(x, p), colors='b', lw=5, alpha=0.5)\n",
    "    ax[1].set_xlim([-0.5,1.5]);\n",
    "    ax[1].set_ylim([0,1.05]);\n",
    "    ax[1].set_title('Likelihood')\n",
    "    ax[1].legend();\n",
    "    ax[1].set_xticks([0, 1])\n",
    "    ax[1].set_xticklabels([\"0\", \"1.\"]);\n",
    "    \n",
    "\n",
    "#Bernoulli\n",
    "w_par_p = widgets.FloatSlider(value = 0.5, description = 'p: ', step = 0.01, min = 0, max = 1)\n",
    "\n",
    "#Beta(1,1) es uniforme. Busque en internet la distribucion Beta; conozcala.\n",
    "w_par_a = widgets.BoundedIntText(value = 1, description = 'a (num): ',\n",
    "                                 min = 1, max = 1000000)\n",
    "w_par_b = widgets.BoundedIntText(value = 1, description = 'b (den-num): ',\n",
    "                                 min = 1, max = 1000000)\n",
    "out = widgets.interactive_output(beta_bernoulli, \n",
    "                                 {'p': w_par_p, \n",
    "                                  'a': w_par_a, 'b': w_par_b})\n",
    "right_widgets = VBox([w_par_p])\n",
    "left_widgets = VBox([w_par_a, w_par_b])\n",
    "top = HBox([left_widgets, right_widgets])\n",
    "VBox([top, out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The typical Bayesian setup, without the marginal, is to define likelihoods and priors: \n",
    "<center><img src=\"img/2_CB/bayes_framework.gv.svg\" width = \"550\" height = '350'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The typical Bayesian setup, without the marginal, is to define likelihoods and priors:\n",
    "\n",
    "$$posterior \\propto prior \\times likelihood$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Prior (our model for beliefs) & likelihood (our model for the data):\n",
    "\n",
    "$$posterior \\propto Beta \\times Bernoulli$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's plug in the formulas\n",
    "\n",
    "$$P(\\theta|successes,tries,\\alpha,\\beta,p) \\propto \\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha,\\beta)} \\times p^{successes}(1-p)^{tries-successes}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Algebra:<br>\n",
    "pars = $\\alpha,\\beta,p$ <br>\n",
    "N = tries<br>\n",
    "z = successes\n",
    "\n",
    "\\begin{align*}\n",
    "  p(\\theta|z,N,pars) &\\propto \\theta^z(1-\\theta)^{N-z}\\frac{\\theta^{\\alpha-1}(1-\\theta)^{\\beta-1}}{B(\\alpha,\\beta)} \n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's add exponents\n",
    "\\begin{align*}\n",
    "  p(\\theta|z,N,pars) &\\propto ... \\\\\n",
    "  &\\propto \\frac{\\theta^{z+\\alpha-1}(1-\\theta)^{N-z+\\beta-1}}{B(\\alpha,\\beta)}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\\begin{equation}\n",
    "  p(\\theta|z,N,pars) \\propto \\frac{\\theta^{z+\\alpha-1}(1-\\theta)^{N-z+\\beta-1}}{B(\\alpha,\\beta)}\n",
    "\\end{equation}\n",
    "\n",
    "Notice that the numerator is the same as a beta with these parameters:\n",
    "\n",
    "$$\\alpha_{posterior} = z + \\alpha$$\n",
    "$$\\beta_{posterior} = N - z + \\beta$$\n",
    "\n",
    "And we know the the normalized version of a beta with the marginal,\n",
    "\n",
    "\\begin{equation}\n",
    "  p(\\theta|z,N,pars) = \\frac{\\theta^{\\alpha_{posterior}-1}(1-\\theta)^{N-z+\\beta_{posterior}-1}}{B(\\alpha_{posterior},\\beta_{posterior})}\n",
    "\\end{equation} \n",
    "\n",
    "In other words, we proved that the posterior is a beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's analyze the result\n",
    "$$ p(\\theta|z,N,\\alpha,\\beta) \\sim beta(z+\\alpha, N-z+\\beta) $$ \n",
    "\n",
    "The posterior includes data (N,z) and previous beliefs ($\\alpha$, $\\beta$).\n",
    "\n",
    "We started with a beta for the prior and a Bernoulli for the likelihood. We ended with a posterior beta, thus the prior was a conjugate (https://en.wikipedia.org/wiki/Conjugate_prior).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Important Bayesian lesson:\n",
    "\n",
    "If the data is good, and the prior is weak, the data dominates the posterior. For instance: \n",
    "\n",
    "$$ p(\\theta|z=3750, N=10.000,\\alpha=5,\\beta=9) \\sim beta(3750+5, 10.000-z+9) $$ \n",
    "\n",
    "Or if the prior is strong and the data weak, the prior dominates the posterior. For instance:\n",
    "\n",
    "$$ p(\\theta|z=11, N=44,\\alpha=5.000,\\beta=9.000) \\sim beta(11+5.000, 44-11+9.000) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Important Bayesian lesson (visually):\n",
    "\n",
    "There is \"tug of war\" between prior beliefs and likelihood of the data for the final posterior beliefs.\n",
    "\n",
    "<center><img src=\"img/2_CB/Prior_vs_LH.svg\" width = \"551\" height = '550'></center>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Analytical derivation of a normal posterior \n",
    "### Likelihood: Normal\n",
    "### Prior: Normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Likelihood (normal)\n",
    "$$ p(y|\\theta) = \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{1}{2\\sigma^2}(y-\\theta)^2}$$\n",
    "\n",
    "Prior (normal)\n",
    "$$ p(\\theta) = \\frac{1}{\\sqrt{2\\pi}\\tau_0}e^{-\\frac{1}{2\\tau_0^2}(\\theta-\\mu_0)^2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The typical Bayesian setup, without the marginal, is to define likelihoods and priors: \n",
    "<center><img src=\"img/2_CB/bayes_framework.gv.svg\" width = \"550\" height = '350'></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The typical Bayesian setup, without the marginal, is to define likelihoods and priors:\n",
    "\n",
    "$$posterior \\propto prior \\times likelihood$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Prior (our model for beliefs) & likelihood (our model for the data):\n",
    "\n",
    "$$posterior \\propto Normal (\\mu_0,\\tau_0^2) \\times Normal(\\theta,\\sigma^2)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's plug in the formulas:\n",
    "\n",
    "$$P(\\theta|y, \\sigma,\\tau_0,\\mu_0) \\propto \\frac{1}{\\sqrt{2\\pi}\\sigma}e^{-\\frac{1}{2\\sigma^2}(y-\\theta)^2}\\times \\frac{1}{\\sqrt{2\\pi}\\tau_0}e^{-\\frac{1}{2\\tau_0^2}(\\theta-\\mu_0)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Algebra!! Let's drop constants (i.e. does not change the proportionality)\n",
    "\\begin{align}\n",
    " &\\propto e^{-\\frac{1}{2\\sigma^2}(y-\\theta)^2}\\times e^{-\\frac{1}{2\\tau_0^2}(\\theta-\\mu_0)^2}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Add exponents\n",
    "\n",
    "\\begin{align}\n",
    "     &\\propto e^{-\\frac{1}{2}\\left(\\frac{(y-\\theta)^2}{\\sigma^2} + \\frac{(\\theta-\\mu_0)^2}{\\tau_0^2}\\right)}\\\\\n",
    "    &\\propto e^{-\\frac{1}{2\\sigma^2\\tau_0^2}\\left(\\tau_0^2(y-\\theta)^2 + \\sigma^2(\\theta-\\mu_0)^2\\right)}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Expand squares\n",
    "\n",
    "\\begin{align}\n",
    "    &\\propto e^{-\\frac{1}{2\\sigma^2\\tau_0^2}\\left(\\tau_0^2(y^2-2\\theta y + \\theta^2) + \\sigma^2(\\theta^2-2\\theta\\mu_0+\\mu_0^2)\\right)}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Group terms with $\\theta$ and drop constants\n",
    "\n",
    "\\begin{align}\n",
    "    &\\propto e^{-\\frac{1}{2\\sigma^2\\tau_0^2}\\left( \\tau_0^2\\theta^2 + \\sigma^2\\theta^2-\\sigma^22\\theta\\mu_0-\\tau_0^22\\theta y + \\sigma^2\\mu_0^2 + \\tau_0^2y^2\\right)}\\\\\n",
    "    &\\propto e^{-\\frac{1}{2\\sigma^2\\tau_0^2}\\left( \\theta^2(\\tau_0^2 + \\sigma^2) - 2\\theta(\\sigma^2\\mu_0 + \\tau_0^2 y)  + \\sigma^2\\mu_0^2 + \\tau_0^2y^2\\right)}\\\\\n",
    "    &\\propto e^{-\\frac{1}{2\\sigma^2\\tau_0^2}\\left( \\theta^2(\\tau_0^2 + \\sigma^2) - 2\\theta(\\sigma^2\\mu_0 + \\tau_0^2 y)\\right)}e^{\\frac{\\sigma^2\\mu_0^2 + \\tau_0^2y^2}{2\\sigma^2\\tau_0^2}}\\\\\n",
    "    &\\propto e^{-\\frac{1}{2\\sigma^2\\tau_0^2}\\left( \\theta^2(\\tau_0^2 + \\sigma^2) - 2\\theta(\\sigma^2\\mu_0 + \\tau_0^2 y)\\right)}\\\\\n",
    "    &\\propto e^{-\\frac{1}{\\frac{2\\sigma^2\\tau_0^2}{\\tau_0^2 + \\sigma^2}}\\left( \\theta^2 - \\frac{2\\theta(\\sigma^2\\mu_0 + \\tau_0^2 y)}{\\tau_0^2 + \\sigma^2}\\right)}\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Complete squares <br>\n",
    "If we have: $\\theta^2 + b\\theta$; <br> \n",
    "Complete with: $\\theta^2 + b\\theta + \\left(\\frac{b}{2}\\right)^2 -\\left(\\frac{b}{2}\\right)^2 = \\left(x+\\frac{b}{2}\\right)^2 - \\left(\\frac{b}{2}\\right)^2 $\n",
    "\n",
    "\\begin{align}\n",
    "    &\\propto e^{-\\frac{1}{\\frac{2\\sigma^2\\tau_0^2}{\\tau_0^2 + \\sigma^2}}\\left( \\theta^2 - \\frac{2\\theta(\\sigma^2\\mu_0 + \\tau_0^2 y)}{\\tau_0^2 + \\sigma^2}\\right)}\\\\\n",
    "    &\\propto e^{-\\frac{1}{\\frac{2\\sigma^2\\tau_0^2}{\\tau_0^2 + \\sigma^2}}\\left( \\theta^2 - \\frac{2\\theta(\\sigma^2\\mu_0 + \\tau_0^2 y)}{\\tau_0^2 + \\sigma^2} + \\left(\\frac{2(\\sigma^2\\mu_0 + \\tau_0^2 y)}{2(\\tau_0^2 + \\sigma^2)}\\right)^2 -\\left(\\frac{2(\\sigma^2\\mu_0 + \\tau_0^2 y)}{2(\\tau_0^2 + \\sigma^2)}\\right)^2\\right)}\\\\\n",
    "    &\\propto e^{-\\frac{1}{\\frac{2\\sigma^2\\tau_0^2}{\\tau_0^2 + \\sigma^2}}\\left(\\left(\\theta - \\frac{(\\sigma^2\\mu_0 + \\tau_0^2 y)}{\\tau_0^2 + \\sigma^2}\\right)^2 -\\left(\\frac{2(\\sigma^2\\mu_0 + \\tau_0^2 y)}{2(\\tau_0^2 + \\sigma^2)}\\right)^2\\right)}\\\\\n",
    "    &\\propto e^{-\\frac{1}{\\frac{2\\sigma^2\\tau_0^2}{\\tau_0^2 + \\sigma^2}}\\left(\\left(\\theta - \\frac{(\\sigma^2\\mu_0 + \\tau_0^2 y)}{\\tau_0^2 + \\sigma^2}\\right)^2\\right)}e^{-\\left(\\frac{2(\\sigma^2\\mu_0 + \\tau_0^2 y)}{2(\\tau_0^2 + \\sigma^2)}\\right)^2}\\\\\n",
    "    &\\propto e^{-\\frac{1}{\\frac{2\\sigma^2\\tau_0^2}{\\tau_0^2 + \\sigma^2}}\\left(\\left(\\theta - \\frac{(\\sigma^2\\mu_0 + \\tau_0^2 y)}{\\tau_0^2 + \\sigma^2}\\right)^2\\right)}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The posterior is $Normal(\\mu_1,\\sigma_1^2)$\n",
    "\n",
    "\\begin{align}\n",
    "P(\\theta|y, \\sigma,\\tau_0,\\mu_0) &\\propto e^{-\\frac{1}{\\frac{2\\sigma^2\\tau_0^2}{\\tau_0^2 + \\sigma^2}}\\left(\\left(\\theta - \\frac{(\\sigma^2\\mu_0 + \\tau_0^2 y)}{\\tau_0^2 + \\sigma^2}\\right)^2\\right)}\n",
    "\\end{align}\n",
    "\n",
    "$\\mu_1 = \\frac{(\\sigma^2\\mu_0 + \\tau_0^2 y)}{\\tau_0^2 + \\sigma^2} = \\frac{\\tau_0^{-2}\\mu_0 + \\sigma^{-2} y}{\\tau_0^{-2} + \\sigma^{-2}}$ \n",
    "\n",
    "$\\sigma_1 = \\frac{\\sigma^2\\tau_0^2}{\\tau_0^2 + \\sigma^2} = \\frac{1}{\\frac{1}{\\sigma^2} + \\frac{1}{\\tau_0^2}}$\n",
    "\n",
    "Note: the 2nd equal in $\\mu_1$ y $\\sigma_1$ is obtained by dividing the numerator and denominator by $\\frac{1}{\\sigma^2\\tau_0^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's analyze the result:\n",
    "\n",
    "$\\mu_1 = \\frac{\\tau_0^{-2}\\mu_0 + \\sigma^{-2} y}{\\tau_0^{-2} + \\sigma^{-2}}$ \n",
    "\n",
    "$\\sigma_1^2 = \\frac{1}{\\frac{1}{\\sigma^2} + \\frac{1}{\\tau_0^2}}$\n",
    "\n",
    "The mean of the posterior is a compromise between data ($y$) and the prior mean ($\\mu_0$). The compromise scales with the variance of the likelihood and the prior.\n",
    "\n",
    "The posterior variance is always lower than the variance of the likelihood and the prior.\n",
    "\n",
    "Note: if $y$ are n data points, change $y$ by it's mean and divide $\\sigma^2$ by n; the final posterior is similar. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Important Bayesian lesson (visually):\n",
    "\n",
    "There is \"tug of war\" between prior beliefs and likelihood of the data for the final posterior beliefs.\n",
    "\n",
    "<center><img src=\"img/2_CB/Prior_vs_LH.svg\" width = \"551\" height = '550'></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9ebd2fadc84d89ba72aa2c34d6c798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(IntSlider(value=10, description='N data: ', min=1), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def normal_normal(muestras):\n",
    "    #Objective: estimate the mean value of a process given some data\n",
    "    #Model: Normal-Normal\n",
    "    np.random.seed(seed=1144)\n",
    "    #muestras = 20\n",
    "    datos_par = [0,1]#mu, sd\n",
    "    evidencia = np.sort(st.norm.rvs(size = muestras, #muestras is samples in english\n",
    "                                    loc = datos_par[0], \n",
    "                                    scale = datos_par[1])) #normal data (evidence)\n",
    "    prior_par = [-10, 1] #mu, sd\n",
    "    likelihood_par = [3] #sd\n",
    "    hipotesis = np.linspace(-20,20,200) #hypotheses space\n",
    "    likelihood = []\n",
    "    for i in range(len(hipotesis)):\n",
    "        lh = np.sum(st.norm.pdf(evidencia,\n",
    "                                loc = hipotesis[i],\n",
    "                                scale = likelihood_par[0]))\n",
    "        likelihood.append(lh) #Likelihood without normalizing constant\n",
    "    prior = st.norm.pdf(hipotesis,\n",
    "                        loc = prior_par[0],\n",
    "                        scale = prior_par[1])\n",
    "    A = prior_par[0]/(prior_par[1]**2)\n",
    "    B = evidencia.mean()/(likelihood_par[0]**2/muestras)                  \n",
    "    C = 1/(prior_par[1]**2)\n",
    "    D = 1/(likelihood_par[0]**2/muestras)\n",
    "    post_par = [round((A + B)/(C + D),2),\n",
    "               round(np.sqrt(1/(C+D)),2)]\n",
    "    posterior = st.norm.pdf(hipotesis,\n",
    "                        loc = post_par[0],\n",
    "                        scale = post_par[1])\n",
    "\n",
    "    fig, ax = plt.subplots(1,1,figsize = (10,5))\n",
    "    #Prior\n",
    "    y = prior/np.max(prior)\n",
    "    idx = y>0.001\n",
    "    ax.plot(hipotesis[idx], y[idx], 'r-', lw=2, alpha=0.6, \n",
    "            label='Prior normal('+ str(prior_par[0]) + ','+ str(prior_par[1]) +')')\n",
    "    #Likelihood\n",
    "    y = likelihood/np.max(likelihood)\n",
    "    idx = y>0.001\n",
    "    ax.plot(hipotesis[idx], y[idx], 'b-', lw=2, alpha=0.6, \n",
    "            label='Likelihood normal('+ 'hipotheses' + ','+ str(likelihood_par[0]) +')')\n",
    "    #Posterior\n",
    "    y = posterior/np.max(posterior)\n",
    "    idx = y>0.00001\n",
    "    ax.plot(hipotesis[idx], y[idx], 'g-', lw=2, alpha=0.6, \n",
    "            label='Posterior normal('+ str(post_par[0]) + ','+ str(post_par[1]) +')')\n",
    "    #Realidad\n",
    "    ax.plot(np.repeat(datos_par[0],100),\n",
    "           np.linspace(0,1,100),'k--',lw=2,\n",
    "           label = 'Real')\n",
    "    ax.legend()\n",
    "    ax.set_xlim([np.min(hipotesis), np.max(hipotesis)])\n",
    "    ax.set_xlabel('Hipotheses')\n",
    "    ax.set_ylabel('Probability \\n (density standardized to the max)');\n",
    "    #fig.savefig('img/2_CB/norm_norm.svg')\n",
    "\n",
    "wN = widgets.IntSlider(value=10, min = 1, max = 100,\n",
    "                       description='N data: ')\n",
    "\n",
    "out = widgets.interactive_output(normal_normal, \n",
    "                                 {'muestras': wN})\n",
    "\n",
    "VBox([wN, out])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Some results and definitions from probability theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Definitions\n",
    "* Conditional probability: $p(u|v)$\n",
    "* Marginal probability: $p(u) = \\int p(u,v) dv$\n",
    "* Joint probability: $p(u,v) = p(u|v)p(v)$\n",
    "* Posterior predictive distribution (de $\\tilde{obs}$): $p(\\tilde{obs}|obs) = \\int p(\\tilde{obs}|\\theta)p(\\theta|obs)d\\theta$\n",
    "* Expected value $E(u)$: $\\int up(u)du$\n",
    "* Variance $var(u)$: $\\int (u - E(u))(u - E(u))^Tp(u)du$\n",
    "\n",
    "Results \n",
    "* Chain rule. Example with 3 variables: $p(u,v,w) = p(u|v,w)p(v,w) = p(u|v,w)p(v|w)p(w)$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Bayes provided us with a way to update beliefs with data\n",
    "\n",
    "The new beliefs are a compromise between data and prior beliefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to slides --SlidesExporter.reveal_theme='solarized' --SlidesExporter.reveal_transition='none' --SlidesExporter.reveal_scroll=True 2_Conociendo_Bayes.ipynb #Saves slide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\n",
    "Para salvar las diapositivas a PDF (en Chrome), correr nbconvert para que abra las diapositivas en un servidor local (la transition y el theme son opcionales):\n",
    "\n",
    "!jupyter nbconvert --to slides --SlidesExporter.reveal_theme='solarized' --SlidesExporter.reveal_transition='convex' nombre_de_mi_notebook.ipynb --post serve\n",
    "\n",
    "Luego, a la dirección añadirle ?print-pdf después del .html:\n",
    "\n",
    "http://127.0.0.1:8000/nombre_de_mi_notebook.slides.html?print-pdf\n",
    "\n",
    "Y luego, imprimir y darle salvar como pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#Para salvar a pdf\n",
    "!jupyter nbconvert --to slides --SlidesExporter.reveal_theme='solarized' --SlidesExporter.reveal_transition='convex' 2_Conociendo_Bayes.ipynb --post serve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Anexos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12,4))\n",
    "x = np.linspace(st.norm.ppf(0.01),st.norm.ppf(0.99), 100)\n",
    "\n",
    "ax[0].plot(x, st.norm.pdf(x),'r-', lw=5, alpha=0.8, label='norm pdf')\n",
    "ax[0].set_xlabel('Hipótesis (e.g. riesgo relativo)')\n",
    "ax[0].set_ylabel('Densidad')\n",
    "ax[0].set_title('Normal')\n",
    "mu = 10\n",
    "x = np.arange(st.poisson.ppf(0.01, mu), st.poisson.ppf(0.99, mu))\n",
    "ax[1].plot(x, st.poisson.pmf(x, mu), 'bo', ms=8, label='poisson pmf')\n",
    "ax[1].vlines(x, 0, st.poisson.pmf(x, mu), colors='b', lw=5, alpha=0.5)\n",
    "ax[1].set_xlabel('Hipótesis (e.g. ataques de ansiedad por día)')\n",
    "ax[1].set_ylabel('Densidad')\n",
    "ax[1].set_title('Poisson')\n",
    "fig.savefig('img/2_CB/normal_poisson.svg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8,4))\n",
    "a, b = 2, 4\n",
    "x = np.linspace(st.beta.ppf(0.001,a,b),st.beta.ppf(0.999,a,b), 100)\n",
    "\n",
    "ax.plot(x, st.beta.pdf(x,a,b),'r-', lw=5, alpha=0.8, label='beta pdf')\n",
    "ax.set_xlabel('Hipótesis')\n",
    "ax.set_ylabel('Densidad')\n",
    "ax.set_title('Beta')\n",
    "ax.set_frame_on(False)\n",
    "fig.savefig('img/2_CB/beta.svg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Visualización Bernoulli y Beta\n",
    "fig, ax = plt.subplots(1,2,figsize = (10,4))\n",
    "a, b = 2, 3\n",
    "x = np.linspace(st.beta.ppf(0.001, a, b), st.beta.ppf(0.999, a, b), 100)\n",
    "ax[0].plot(x, st.beta.pdf(x, a, b), 'r-', lw=5, alpha=0.6, label='beta pdf')\n",
    "ax[0].set_title('Prior')\n",
    "ax[0].legend()\n",
    "\n",
    "p = 0.3 #prob. de éxito\n",
    "x = np.linspace(st.bernoulli.ppf(0.001, p), st.bernoulli.ppf(0.999, p),2)\n",
    "ax[1].plot(x, st.bernoulli.pmf(x, p), 'bo', ms=8, label='bernoulli pmf')\n",
    "ax[1].vlines(x, 0, st.bernoulli.pmf(x, p), colors='b', lw=5, alpha=0.5)\n",
    "ax[1].set_xlim([-0.5,1.5]);\n",
    "ax[1].set_title('Likelihood')\n",
    "ax[1].legend();\n",
    "ax[1].set_xticks([0, 1])\n",
    "ax[1].set_xticklabels([\"0\", \"1.\"]);\n",
    "fig.savefig('img/2_CB/beta_bernoulli.svg');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "#Graphical models with graphviz (http://www.graphviz.org/pdf/dotguide.pdf)\n",
    "\n",
    "#Example 1 (graph with different shapes)\n",
    "dot_text = 'digraph G {a -> b -> c;\\\n",
    "                       b -> d;\\\n",
    "                       a [shape=circle,peripheries=2,color=gray,style=filled];\\\n",
    "                       c [shape=polygon,sides=4,skew=.4,label=\"recuado bogota\"];\\\n",
    "                       d [shape=invtriangle];\\\n",
    "                       e [shape=polygon,sides=4,distortion=.7];\\\n",
    "                       }' #warning: use single quote at start and end; double quotes for labels\n",
    "src = Source(dot_text)\n",
    "src.render('img/2_CB/test.gv', format ='svg', view=False)\n",
    "#display(src)\n",
    "\n",
    "\n",
    "#Example 2 (graph with edges on clusters)\n",
    "dot_text = 'digraph G {compound=true;\\\n",
    "                       subgraph cluster0 {a -> b;a -> c;b -> d;c -> d;\\\n",
    "                                          subgraph cluster1 {a; b; c}\\\n",
    "                                          }\\\n",
    "                       subgraph cluster2 {e -> g;e -> f;}\\\n",
    "                       b -> f [lhead=cluster2];\\\n",
    "                       d -> e;\\\n",
    "                       c -> g [ltail=cluster0,lhead=cluster2];\\\n",
    "                       c -> e [ltail=cluster0];\\\n",
    "                       d -> h;\\\n",
    "                       b[shape=circle,peripheries=2,color=gray,style=filled];\\\n",
    "                       }' #warning: use single quote at start and end; double quotes for labels\n",
    "src = Source(dot_text)\n",
    "src.render('img/2_CB/test2.gv', format ='svg', view=False);\n",
    "#display(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "dot_text = 'digraph G {rankdir=LR;\\\n",
    "                       a -> c;\\\n",
    "                       b -> c;\\\n",
    "                       a [shape=polygon,sides=4,label=\"Prior\\n(creencias)\"];\\\n",
    "                       b [shape=polygon,sides=4,label=\"Likelihood\\n(evidencia)\"];\\\n",
    "                       c [shape=polygon,sides=4,label=\"Posterior\\n(nuevas creencias)\"];\\\n",
    "                       }' #warning: use single quote at start and end; double quotes for labels\n",
    "src = Source(dot_text)\n",
    "src.render('img/2_CB/bayes_framework.gv', format ='svg', view=False)\n",
    "display(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Visualización lucha likelihood vs prior para dominar posterior\n",
    "fig, ax = plt.subplots(1,1,figsize = (10,5))\n",
    "#Prior\n",
    "a, b = 10, 40\n",
    "x = np.linspace(st.beta.ppf(0.001, a, b), st.beta.ppf(0.999, a, b), 100)\n",
    "y = st.beta.pdf(x, a, b)\n",
    "ax.plot(x, y/np.max(y), 'r-', lw=2, alpha=0.6, \n",
    "        label='Prior beta('+ str(a) + ','+ str(b) +')')\n",
    "\n",
    "#Likelihood\n",
    "N = 40 #Intentos\n",
    "z = 32 #Exitos\n",
    "p = np.linspace(0.6,1,100) #hipótesis prob. de éxito\n",
    "bernoulli_pmf = p**z*(1-p)**(N-z) #likelihood \n",
    "y = bernoulli_pmf\n",
    "ax.plot(p, y/np.max(y), 'b-', lw=2, \n",
    "        label='Likelihood Bernoulli.\\nExitos: ' + str(z) + ', ' + 'Intentos: ' + str(N))\n",
    "ax.legend();\n",
    "\n",
    "#Posterior\n",
    "a, b = z+a, N-z+b\n",
    "x = np.linspace(st.beta.ppf(0.001, a, b), st.beta.ppf(0.999, a, b), 100)\n",
    "y = st.beta.pdf(x, a, b)\n",
    "ax.plot(x, y/np.max(y), 'g-', lw=2, alpha=0.6, \n",
    "        label='Posterior beta('+ str(a) + ','+ str(b) +')')\n",
    "ax.legend()\n",
    "\n",
    "ax.set_title('Posterior: Prior vs. Likelihood', fontsize = 20)\n",
    "ax.set_ylabel('Probabilidad \\n (relativo al max)', fontsize = 20)\n",
    "ax.set_xlabel('Hipótesis (prob. de exito)', fontsize = 20)\n",
    "ax.set_xlim([-0.05,1.05]);\n",
    "ax.set_ylim([0,1.5]);\n",
    "ax.legend(loc = 'upper right', fontsize = 12)\n",
    "plt.tight_layout\n",
    "fig.savefig('img/2_CB/Prior_vs_LH.svg');"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "rise": {
   "chalkboard": {
    "color": [
     "rgb(250, 0, 0)",
     "rgb(0, 250, 250)"
    ]
   },
   "enable_chalkboard": true,
   "scroll": true,
   "theme": "simple",
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
